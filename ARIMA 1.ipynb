{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import rcParams\n",
    "rcParams['figure.figsize'] = (15,6)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0      int64\n",
      "Year            int64\n",
      "Month           int64\n",
      "Day             int64\n",
      "Hour            int64\n",
      "AP            float64\n",
      "C6            float64\n",
      "CO            float64\n",
      "NO            float64\n",
      "NO2           float64\n",
      "NOX           float64\n",
      "O3            float64\n",
      "PM10          float64\n",
      "PM25          float64\n",
      "RF            float64\n",
      "RH            float64\n",
      "RT            float64\n",
      "SO2           float64\n",
      "SR            float64\n",
      "TOL           float64\n",
      "WD            float64\n",
      "WS            float64\n",
      "XYL           float64\n",
      "dtype: object\n",
      "                  Unnamed: 0  Year  Month  Day  Hour      AP    C6    CO  \\\n",
      "period                                                                     \n",
      "01-01-2016 00:00           0  2016      1    1     0  953.25  0.46  1.51   \n",
      "01-01-2016 01:00           1  2016      1    1     1  952.98  0.27  1.22   \n",
      "01-01-2016 02:00           2  2016      1    1     2  952.69  0.14  1.05   \n",
      "01-01-2016 03:00           3  2016      1    1     3  952.45  0.17  0.98   \n",
      "01-01-2016 04:00           4  2016      1    1     4  952.43  0.12  0.93   \n",
      "\n",
      "                     NO    NO2  ...    PM25   RF     RH     RT    SO2    SR  \\\n",
      "period                          ...                                           \n",
      "01-01-2016 00:00  20.11  68.99  ...   75.25  0.0  58.18  17.72  40.58  0.11   \n",
      "01-01-2016 01:00  20.50  68.79  ...  101.77  0.0  61.08  16.91  40.46  0.02   \n",
      "01-01-2016 02:00  20.89  66.25  ...   83.33  0.0  62.52  16.43  38.97  0.01   \n",
      "01-01-2016 03:00  21.09  66.43  ...   61.98  0.0  64.72  15.66  39.07  0.00   \n",
      "01-01-2016 04:00  21.21  67.40  ...   69.20  0.0  68.06  14.93  39.65  0.00   \n",
      "\n",
      "                   TOL     WD    WS   XYL  \n",
      "period                                     \n",
      "01-01-2016 00:00  3.23  16.39  0.41  2.35  \n",
      "01-01-2016 01:00  2.18  16.33  0.53  1.53  \n",
      "01-01-2016 02:00  1.65  16.30  0.45  1.08  \n",
      "01-01-2016 03:00  1.30  16.25  0.29  0.76  \n",
      "01-01-2016 04:00  1.15  16.23  0.28  0.60  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('ALL_MONTHS_FINAL.csv')\n",
    "data = data.set_index('period')\n",
    "print(data.dtypes)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.loc[:,['Month','Day','Hour','AP','C6','CO','NO','NO2','NOX','O3','RF','RT','RH','SO2','SR','TOL','WD','WS','XYL']]\n",
    "y = data.loc[:,['PM25']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting multiple linear regression to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14640107344326536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>PM25</td>       <th>  R-squared:         </th> <td>   0.161</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   112.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 01 Jul 2019</td> <th>  Prob (F-statistic):</th> <td>1.32e-319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:26:49</td>     <th>  Log-Likelihood:    </th> <td> -51405.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8784</td>      <th>  AIC:               </th> <td>1.028e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8768</td>      <th>  BIC:               </th> <td>1.030e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -955.9903</td> <td>  164.012</td> <td>   -5.829</td> <td> 0.000</td> <td>-1277.492</td> <td> -634.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1631</td> <td>    0.344</td> <td>   -0.475</td> <td> 0.635</td> <td>   -0.837</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0955</td> <td>    0.105</td> <td>    0.909</td> <td> 0.363</td> <td>   -0.110</td> <td>    0.302</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3369</td> <td>    0.152</td> <td>    2.220</td> <td> 0.026</td> <td>    0.039</td> <td>    0.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.1442</td> <td>    0.170</td> <td>    6.729</td> <td> 0.000</td> <td>    0.811</td> <td>    1.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   53.2853</td> <td>    3.137</td> <td>   16.984</td> <td> 0.000</td> <td>   47.135</td> <td>   59.435</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    8.4169</td> <td>    0.964</td> <td>    8.734</td> <td> 0.000</td> <td>    6.528</td> <td>   10.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.5510</td> <td>    0.431</td> <td>    1.277</td> <td> 0.201</td> <td>   -0.295</td> <td>    1.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.0118</td> <td>    0.420</td> <td>   -0.028</td> <td> 0.978</td> <td>   -0.835</td> <td>    0.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.0593</td> <td>    0.420</td> <td>   -0.141</td> <td> 0.888</td> <td>   -0.883</td> <td>    0.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.3013</td> <td>    0.117</td> <td>   -2.581</td> <td> 0.010</td> <td>   -0.530</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>  -10.7811</td> <td>   21.078</td> <td>   -0.511</td> <td> 0.609</td> <td>  -52.099</td> <td>   30.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -2.4466</td> <td>    0.316</td> <td>   -7.742</td> <td> 0.000</td> <td>   -3.066</td> <td>   -1.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.7705</td> <td>    0.087</td> <td>   -8.844</td> <td> 0.000</td> <td>   -0.941</td> <td>   -0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>   -0.1504</td> <td>    0.078</td> <td>   -1.920</td> <td> 0.055</td> <td>   -0.304</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>    0.0376</td> <td>    0.008</td> <td>    4.895</td> <td> 0.000</td> <td>    0.023</td> <td>    0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17460.343</td> <th>  Durbin-Watson:     </th>   <td>   1.624</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>34774730.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>16.303</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>309.512</td>  <th>  Cond. No.          </th>   <td>1.76e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.76e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   PM25   R-squared:                       0.161\n",
       "Model:                            OLS   Adj. R-squared:                  0.160\n",
       "Method:                 Least Squares   F-statistic:                     112.1\n",
       "Date:                Mon, 01 Jul 2019   Prob (F-statistic):          1.32e-319\n",
       "Time:                        01:26:49   Log-Likelihood:                -51405.\n",
       "No. Observations:                8784   AIC:                         1.028e+05\n",
       "Df Residuals:                    8768   BIC:                         1.030e+05\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -955.9903    164.012     -5.829      0.000   -1277.492    -634.488\n",
       "x1            -0.1631      0.344     -0.475      0.635      -0.837       0.510\n",
       "x2             0.0955      0.105      0.909      0.363      -0.110       0.302\n",
       "x3             0.3369      0.152      2.220      0.026       0.039       0.634\n",
       "x4             1.1442      0.170      6.729      0.000       0.811       1.477\n",
       "x5            53.2853      3.137     16.984      0.000      47.135      59.435\n",
       "x6             8.4169      0.964      8.734      0.000       6.528      10.306\n",
       "x7             0.5510      0.431      1.277      0.201      -0.295       1.397\n",
       "x8            -0.0118      0.420     -0.028      0.978      -0.835       0.812\n",
       "x9            -0.0593      0.420     -0.141      0.888      -0.883       0.764\n",
       "x10           -0.3013      0.117     -2.581      0.010      -0.530      -0.072\n",
       "x11          -10.7811     21.078     -0.511      0.609     -52.099      30.537\n",
       "x12           -2.4466      0.316     -7.742      0.000      -3.066      -1.827\n",
       "x13           -0.7705      0.087     -8.844      0.000      -0.941      -0.600\n",
       "x14           -0.1504      0.078     -1.920      0.055      -0.304       0.003\n",
       "x15            0.0376      0.008      4.895      0.000       0.023       0.053\n",
       "==============================================================================\n",
       "Omnibus:                    17460.343   Durbin-Watson:                   1.624\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         34774730.011\n",
       "Skew:                          16.303   Prob(JB):                         0.00\n",
       "Kurtosis:                     309.512   Cond. No.                     1.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building the optimal model using backward elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X=np.append(arr=np.ones((8784,1)).astype(int),values = X, axis = 1)\n",
    "\n",
    "X_opt = X[:, [3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]]\n",
    "regressor_OLS = sm.OLS(endog = y , exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>PM25</td>       <th>  R-squared:         </th> <td>   0.161</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.159</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   120.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 01 Jul 2019</td> <th>  Prob (F-statistic):</th> <td>2.66e-320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:26:54</td>     <th>  Log-Likelihood:    </th> <td> -51405.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8784</td>      <th>  AIC:               </th> <td>1.028e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8769</td>      <th>  BIC:               </th> <td>1.029e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -958.8525</td> <td>  164.003</td> <td>   -5.847</td> <td> 0.000</td> <td>-1280.336</td> <td> -637.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.1951</td> <td>    0.343</td> <td>   -0.569</td> <td> 0.569</td> <td>   -0.867</td> <td>    0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0947</td> <td>    0.105</td> <td>    0.901</td> <td> 0.368</td> <td>   -0.111</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3314</td> <td>    0.152</td> <td>    2.185</td> <td> 0.029</td> <td>    0.034</td> <td>    0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.1469</td> <td>    0.170</td> <td>    6.746</td> <td> 0.000</td> <td>    0.814</td> <td>    1.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   53.3785</td> <td>    3.137</td> <td>   17.018</td> <td> 0.000</td> <td>   47.230</td> <td>   59.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    8.4122</td> <td>    0.964</td> <td>    8.729</td> <td> 0.000</td> <td>    6.523</td> <td>   10.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.5190</td> <td>    0.137</td> <td>   -3.790</td> <td> 0.000</td> <td>   -0.787</td> <td>   -0.251</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.4648</td> <td>    0.091</td> <td>    5.113</td> <td> 0.000</td> <td>    0.287</td> <td>    0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.2846</td> <td>    0.116</td> <td>   -2.453</td> <td> 0.014</td> <td>   -0.512</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>  -10.9803</td> <td>   21.078</td> <td>   -0.521</td> <td> 0.602</td> <td>  -52.299</td> <td>   30.338</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -2.4277</td> <td>    0.316</td> <td>   -7.691</td> <td> 0.000</td> <td>   -3.047</td> <td>   -1.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.7712</td> <td>    0.087</td> <td>   -8.852</td> <td> 0.000</td> <td>   -0.942</td> <td>   -0.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -0.1537</td> <td>    0.078</td> <td>   -1.963</td> <td> 0.050</td> <td>   -0.307</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    0.0370</td> <td>    0.008</td> <td>    4.827</td> <td> 0.000</td> <td>    0.022</td> <td>    0.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17462.052</td> <th>  Durbin-Watson:     </th>   <td>   1.619</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>34793455.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>16.306</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>309.595</td>  <th>  Cond. No.          </th>   <td>1.76e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.76e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   PM25   R-squared:                       0.161\n",
       "Model:                            OLS   Adj. R-squared:                  0.159\n",
       "Method:                 Least Squares   F-statistic:                     120.0\n",
       "Date:                Mon, 01 Jul 2019   Prob (F-statistic):          2.66e-320\n",
       "Time:                        01:26:54   Log-Likelihood:                -51405.\n",
       "No. Observations:                8784   AIC:                         1.028e+05\n",
       "Df Residuals:                    8769   BIC:                         1.029e+05\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -958.8525    164.003     -5.847      0.000   -1280.336    -637.369\n",
       "x1            -0.1951      0.343     -0.569      0.569      -0.867       0.477\n",
       "x2             0.0947      0.105      0.901      0.368      -0.111       0.301\n",
       "x3             0.3314      0.152      2.185      0.029       0.034       0.629\n",
       "x4             1.1469      0.170      6.746      0.000       0.814       1.480\n",
       "x5            53.3785      3.137     17.018      0.000      47.230      59.527\n",
       "x6             8.4122      0.964      8.729      0.000       6.523      10.301\n",
       "x7            -0.5190      0.137     -3.790      0.000      -0.787      -0.251\n",
       "x8             0.4648      0.091      5.113      0.000       0.287       0.643\n",
       "x9            -0.2846      0.116     -2.453      0.014      -0.512      -0.057\n",
       "x10          -10.9803     21.078     -0.521      0.602     -52.299      30.338\n",
       "x11           -2.4277      0.316     -7.691      0.000      -3.047      -1.809\n",
       "x12           -0.7712      0.087     -8.852      0.000      -0.942      -0.600\n",
       "x13           -0.1537      0.078     -1.963      0.050      -0.307      -0.000\n",
       "x14            0.0370      0.008      4.827      0.000       0.022       0.052\n",
       "==============================================================================\n",
       "Omnibus:                    17462.052   Durbin-Watson:                   1.619\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         34793455.011\n",
       "Skew:                          16.306   Prob(JB):                         0.00\n",
       "Kurtosis:                     309.595   Cond. No.                     1.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [3,4,5,6,7,8,9,11,12,13,14,15,16,17,18]]\n",
    "regressor_OLS = sm.OLS(endog = y , exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>PM25</td>       <th>  R-squared:         </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.159</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   128.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 01 Jul 2019</td> <th>  Prob (F-statistic):</th> <td>4.56e-320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:26:55</td>     <th>  Log-Likelihood:    </th> <td> -51408.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8784</td>      <th>  AIC:               </th> <td>1.028e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8770</td>      <th>  BIC:               </th> <td>1.029e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -953.2071</td> <td>  164.033</td> <td>   -5.811</td> <td> 0.000</td> <td>-1274.751</td> <td> -631.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -0.4081</td> <td>    0.332</td> <td>   -1.231</td> <td> 0.218</td> <td>   -1.058</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.0680</td> <td>    0.105</td> <td>    0.651</td> <td> 0.515</td> <td>   -0.137</td> <td>    0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3529</td> <td>    0.151</td> <td>    2.330</td> <td> 0.020</td> <td>    0.056</td> <td>    0.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>    1.1348</td> <td>    0.170</td> <td>    6.675</td> <td> 0.000</td> <td>    0.802</td> <td>    1.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   54.4495</td> <td>    3.107</td> <td>   17.525</td> <td> 0.000</td> <td>   48.359</td> <td>   60.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    8.0654</td> <td>    0.954</td> <td>    8.458</td> <td> 0.000</td> <td>    6.196</td> <td>    9.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   -0.4227</td> <td>    0.131</td> <td>   -3.221</td> <td> 0.001</td> <td>   -0.680</td> <td>   -0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.3538</td> <td>    0.079</td> <td>    4.486</td> <td> 0.000</td> <td>    0.199</td> <td>    0.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>  -14.3084</td> <td>   21.041</td> <td>   -0.680</td> <td> 0.496</td> <td>  -55.553</td> <td>   26.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -2.3281</td> <td>    0.313</td> <td>   -7.435</td> <td> 0.000</td> <td>   -2.942</td> <td>   -1.714</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.6964</td> <td>    0.082</td> <td>   -8.530</td> <td> 0.000</td> <td>   -0.856</td> <td>   -0.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>   -0.1420</td> <td>    0.078</td> <td>   -1.816</td> <td> 0.069</td> <td>   -0.295</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.0379</td> <td>    0.008</td> <td>    4.945</td> <td> 0.000</td> <td>    0.023</td> <td>    0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17461.926</td> <th>  Durbin-Watson:     </th>   <td>   1.618</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>34788248.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>16.306</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>309.572</td>  <th>  Cond. No.          </th>   <td>1.76e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.76e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   PM25   R-squared:                       0.160\n",
       "Model:                            OLS   Adj. R-squared:                  0.159\n",
       "Method:                 Least Squares   F-statistic:                     128.7\n",
       "Date:                Mon, 01 Jul 2019   Prob (F-statistic):          4.56e-320\n",
       "Time:                        01:26:55   Log-Likelihood:                -51408.\n",
       "No. Observations:                8784   AIC:                         1.028e+05\n",
       "Df Residuals:                    8770   BIC:                         1.029e+05\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -953.2071    164.033     -5.811      0.000   -1274.751    -631.663\n",
       "x1            -0.4081      0.332     -1.231      0.218      -1.058       0.242\n",
       "x2             0.0680      0.105      0.651      0.515      -0.137       0.273\n",
       "x3             0.3529      0.151      2.330      0.020       0.056       0.650\n",
       "x4             1.1348      0.170      6.675      0.000       0.802       1.468\n",
       "x5            54.4495      3.107     17.525      0.000      48.359      60.540\n",
       "x6             8.0654      0.954      8.458      0.000       6.196       9.935\n",
       "x7            -0.4227      0.131     -3.221      0.001      -0.680      -0.165\n",
       "x8             0.3538      0.079      4.486      0.000       0.199       0.508\n",
       "x9           -14.3084     21.041     -0.680      0.496     -55.553      26.936\n",
       "x10           -2.3281      0.313     -7.435      0.000      -2.942      -1.714\n",
       "x11           -0.6964      0.082     -8.530      0.000      -0.856      -0.536\n",
       "x12           -0.1420      0.078     -1.816      0.069      -0.295       0.011\n",
       "x13            0.0379      0.008      4.945      0.000       0.023       0.053\n",
       "==============================================================================\n",
       "Omnibus:                    17461.926   Durbin-Watson:                   1.618\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         34788248.746\n",
       "Skew:                          16.306   Prob(JB):                         0.00\n",
       "Kurtosis:                     309.572   Cond. No.                     1.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [3,4,5,6,7,8,9,11,12,14,15,16,17,18]]\n",
    "regressor_OLS = sm.OLS(endog = y , exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>PM25</td>       <th>  R-squared:         </th> <td>   0.160</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.159</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   139.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 01 Jul 2019</td> <th>  Prob (F-statistic):</th> <td>8.02e-321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:26:56</td>     <th>  Log-Likelihood:    </th> <td> -51409.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8784</td>      <th>  AIC:               </th> <td>1.028e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8771</td>      <th>  BIC:               </th> <td>1.029e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    12</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -952.7639</td> <td>  164.038</td> <td>   -5.808</td> <td> 0.000</td> <td>-1274.316</td> <td> -631.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0565</td> <td>    0.104</td> <td>    0.542</td> <td> 0.588</td> <td>   -0.148</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.3431</td> <td>    0.151</td> <td>    2.268</td> <td> 0.023</td> <td>    0.047</td> <td>    0.640</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.1347</td> <td>    0.170</td> <td>    6.675</td> <td> 0.000</td> <td>    0.801</td> <td>    1.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   54.2943</td> <td>    3.105</td> <td>   17.489</td> <td> 0.000</td> <td>   48.209</td> <td>   60.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    7.8853</td> <td>    0.942</td> <td>    8.368</td> <td> 0.000</td> <td>    6.038</td> <td>    9.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.4641</td> <td>    0.127</td> <td>   -3.659</td> <td> 0.000</td> <td>   -0.713</td> <td>   -0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.3605</td> <td>    0.079</td> <td>    4.581</td> <td> 0.000</td> <td>    0.206</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -13.9439</td> <td>   21.039</td> <td>   -0.663</td> <td> 0.508</td> <td>  -55.185</td> <td>   27.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -2.3347</td> <td>    0.313</td> <td>   -7.456</td> <td> 0.000</td> <td>   -2.948</td> <td>   -1.721</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.7196</td> <td>    0.079</td> <td>   -9.060</td> <td> 0.000</td> <td>   -0.875</td> <td>   -0.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.1071</td> <td>    0.073</td> <td>   -1.470</td> <td> 0.142</td> <td>   -0.250</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    0.0371</td> <td>    0.008</td> <td>    4.856</td> <td> 0.000</td> <td>    0.022</td> <td>    0.052</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17458.742</td> <th>  Durbin-Watson:     </th>   <td>   1.617</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>34758432.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>16.299</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>309.440</td>  <th>  Cond. No.          </th>   <td>1.76e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.76e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   PM25   R-squared:                       0.160\n",
       "Model:                            OLS   Adj. R-squared:                  0.159\n",
       "Method:                 Least Squares   F-statistic:                     139.3\n",
       "Date:                Mon, 01 Jul 2019   Prob (F-statistic):          8.02e-321\n",
       "Time:                        01:26:56   Log-Likelihood:                -51409.\n",
       "No. Observations:                8784   AIC:                         1.028e+05\n",
       "Df Residuals:                    8771   BIC:                         1.029e+05\n",
       "Df Model:                          12                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -952.7639    164.038     -5.808      0.000   -1274.316    -631.211\n",
       "x1             0.0565      0.104      0.542      0.588      -0.148       0.261\n",
       "x2             0.3431      0.151      2.268      0.023       0.047       0.640\n",
       "x3             1.1347      0.170      6.675      0.000       0.801       1.468\n",
       "x4            54.2943      3.105     17.489      0.000      48.209      60.380\n",
       "x5             7.8853      0.942      8.368      0.000       6.038       9.732\n",
       "x6            -0.4641      0.127     -3.659      0.000      -0.713      -0.215\n",
       "x7             0.3605      0.079      4.581      0.000       0.206       0.515\n",
       "x8           -13.9439     21.039     -0.663      0.508     -55.185      27.298\n",
       "x9            -2.3347      0.313     -7.456      0.000      -2.948      -1.721\n",
       "x10           -0.7196      0.079     -9.060      0.000      -0.875      -0.564\n",
       "x11           -0.1071      0.073     -1.470      0.142      -0.250       0.036\n",
       "x12            0.0371      0.008      4.856      0.000       0.022       0.052\n",
       "==============================================================================\n",
       "Omnibus:                    17458.742   Durbin-Watson:                   1.617\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         34758432.012\n",
       "Skew:                          16.299   Prob(JB):                         0.00\n",
       "Kurtosis:                     309.440   Cond. No.                     1.76e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.76e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [3,5,6,7,8,9,11,12,14,15,16,17,18]]\n",
    "regressor_OLS = sm.OLS(endog = y , exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>PM25</td>       <th>  R-squared:         </th> <td>   0.152</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.151</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   143.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 01 Jul 2019</td> <th>  Prob (F-statistic):</th> <td>2.81e-304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>01:26:56</td>     <th>  Log-Likelihood:    </th> <td> -51450.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8784</td>      <th>  AIC:               </th> <td>1.029e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8772</td>      <th>  BIC:               </th> <td>1.030e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1339.3848</td> <td>  159.120</td> <td>   -8.417</td> <td> 0.000</td> <td>-1651.298</td> <td>-1027.471</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0228</td> <td>    0.105</td> <td>    0.218</td> <td> 0.828</td> <td>   -0.182</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.4029</td> <td>    0.152</td> <td>    2.654</td> <td> 0.008</td> <td>    0.105</td> <td>    0.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    1.4543</td> <td>    0.167</td> <td>    8.705</td> <td> 0.000</td> <td>    1.127</td> <td>    1.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   62.2977</td> <td>    2.990</td> <td>   20.836</td> <td> 0.000</td> <td>   56.437</td> <td>   68.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    7.2880</td> <td>    0.944</td> <td>    7.718</td> <td> 0.000</td> <td>    5.437</td> <td>    9.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.7333</td> <td>    0.124</td> <td>   -5.919</td> <td> 0.000</td> <td>   -0.976</td> <td>   -0.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.5131</td> <td>    0.077</td> <td>    6.644</td> <td> 0.000</td> <td>    0.362</td> <td>    0.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>  -43.3560</td> <td>   20.883</td> <td>   -2.076</td> <td> 0.038</td> <td>  -84.292</td> <td>   -2.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -0.7055</td> <td>    0.258</td> <td>   -2.740</td> <td> 0.006</td> <td>   -1.210</td> <td>   -0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -0.0218</td> <td>    0.073</td> <td>   -0.301</td> <td> 0.764</td> <td>   -0.164</td> <td>    0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    0.0496</td> <td>    0.008</td> <td>    6.575</td> <td> 0.000</td> <td>    0.035</td> <td>    0.064</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17348.703</td> <th>  Durbin-Watson:     </th>   <td>   1.608</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>33427046.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>16.076</td>   <th>  Prob(JB):          </th>   <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>303.495</td>  <th>  Cond. No.          </th>   <td>1.69e+05</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.69e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   PM25   R-squared:                       0.152\n",
       "Model:                            OLS   Adj. R-squared:                  0.151\n",
       "Method:                 Least Squares   F-statistic:                     143.2\n",
       "Date:                Mon, 01 Jul 2019   Prob (F-statistic):          2.81e-304\n",
       "Time:                        01:26:56   Log-Likelihood:                -51450.\n",
       "No. Observations:                8784   AIC:                         1.029e+05\n",
       "Df Residuals:                    8772   BIC:                         1.030e+05\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1339.3848    159.120     -8.417      0.000   -1651.298   -1027.471\n",
       "x1             0.0228      0.105      0.218      0.828      -0.182       0.228\n",
       "x2             0.4029      0.152      2.654      0.008       0.105       0.700\n",
       "x3             1.4543      0.167      8.705      0.000       1.127       1.782\n",
       "x4            62.2977      2.990     20.836      0.000      56.437      68.159\n",
       "x5             7.2880      0.944      7.718      0.000       5.437       9.139\n",
       "x6            -0.7333      0.124     -5.919      0.000      -0.976      -0.490\n",
       "x7             0.5131      0.077      6.644      0.000       0.362       0.664\n",
       "x8           -43.3560     20.883     -2.076      0.038     -84.292      -2.420\n",
       "x9            -0.7055      0.258     -2.740      0.006      -1.210      -0.201\n",
       "x10           -0.0218      0.073     -0.301      0.764      -0.164       0.120\n",
       "x11            0.0496      0.008      6.575      0.000       0.035       0.064\n",
       "==============================================================================\n",
       "Omnibus:                    17348.703   Durbin-Watson:                   1.608\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         33427046.885\n",
       "Skew:                          16.076   Prob(JB):                         0.00\n",
       "Kurtosis:                     303.495   Cond. No.                     1.69e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.69e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [3,5,6,7,8,9,11,12,14,15,17,18]]\n",
    "regressor_OLS = sm.OLS(endog = y , exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_opt_train, X_opt_test, y_opt_train, y__opt_test = train_test_split(X_opt, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting multiple linear regression to the training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor2 = LinearRegression()\n",
    "regressor2.fit(X_opt_train, y_opt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor2.predict(X_opt_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1330091656230089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(r2_score(y__opt_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[86.73792135],\n",
       "       [49.37939285],\n",
       "       [81.42571014],\n",
       "       ...,\n",
       "       [66.02676502],\n",
       "       [69.04129762],\n",
       "       [53.75459067]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PM25    36.62\n",
       "Name: 30-11-2016 14:00, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[-2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data = np.log(data).diff().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "E:\\Anaconda\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "E:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:225: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.api import VAR, DynamicVAR\n",
    "model = VAR(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x already contains a constant",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-d962655acad1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, maxlags, method, ic, trend, verbose)\u001b[0m\n\u001b[0;32m    640\u001b[0m                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_trend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_estimate_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_estimate_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\var_model.py\u001b[0m in \u001b[0;36m_estimate_var\u001b[1;34m(self, lags, offset, trend)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         z = util.get_var_endog(endog, lags, trend=trend,\n\u001b[1;32m--> 664\u001b[1;33m                                has_constant='raise')\n\u001b[0m\u001b[0;32m    665\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexog\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[1;31m# TODO: currently only deterministic terms supported (exoglags==0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\vector_ar\\util.py\u001b[0m in \u001b[0;36mget_var_endog\u001b[1;34m(y, lags, trend, has_constant)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtrend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'nc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         Z = tsa.add_trend(Z, prepend=True, trend=trend,\n\u001b[1;32m---> 36\u001b[1;33m                           has_constant=has_constant)\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py\u001b[0m in \u001b[0;36madd_trend\u001b[1;34m(x, trend, prepend, has_constant)\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_const\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhas_constant\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x already contains a constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mhas_constant\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'skip'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x already contains a constant"
     ]
    }
   ],
   "source": [
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
